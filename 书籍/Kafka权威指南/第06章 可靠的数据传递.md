## 第06章 可靠的数据传递

1. 可靠性需要从整体的系统出发，而不是某一个组件所需要确保的责任。
2. Kafka的可靠性保证：
   1. Kafka可以保证分区消息的顺序。如果使用同一个生产者往同一个分区写入消息，而且消息B在消息A之后写入，那么Kafka可以保证消息B的偏移量比消息A的偏移量大，而且消费者会先读取消息A再读取消息B（分区顺序性）
   2. 只有当消息被写入分区的所有同步副本时（但不一定要写入磁盘），它才被认为是“已提交”的。生产者可以选择接受不同类型的确认，比如在消息完全被提交时的确认，或者在消息被写入首领副本时的确认，或者在消息被发送到网络时的确认。
   3. 只要还有一个副本是活跃的，那么已经提交的消息就不会丢失。
   4. 消费者只能读取已经提交的消息。
3. Kafka的复制机制和分区的多副本架构是Kafka可靠性保证的核心。
4. Kafka的主题被分为多个分区，分区是基本的数据块。分区存储在单个磁盘上，Kafka可以保证分区里的事件是有序的，分区可以在线（可用），也可以离线（不可用）。每个分区可以有多个副本，其中一个副本是首领。所有的事件都直接发送给首领副本，或者直接从首领副本读取事件。其他副本只需要与首领保持同步，并及时复制最新的事件。当首领副本不可用时，其中一个同步副本将成为新首领。
5. 分区首领是同步副本，而对于跟随着副本来说，它需要满足以下条件才能被认为是同步的：
   1. 与 Zookeeper 之间有一个活跃的会话， 也就是说， 它在过去的 6s（可配置）内向 Zookeeper 发送过心跳。
   2. 与 Zookeeper 之间有一个活跃的会话， 也就是说， 它在过去的 6s（可配置）内向 Zookeeper 发送过心跳。
   3. 在过去的 10s 内从首领那里获取过最新的消息。光从首领那里获取消息是不够的，它还 必须是几乎零延迟的。
6. 如果跟随者副本不能满足以上任何一点，比如与 Zookeeper 断开连接，或者不再获取新消 息，或者获取消息滞后了 10s 以上，那么它就被认为是不同步的。一个不同步的副本通过 与 Zookeeper 重新建立连接，并从首领那里获取最新消息，可以重新变成同步的。这个过 程在网络出现临时问题并很快得到修复的情况下会很快完成，但如果 broker 发生崩溃就需 要较长的时间。
7. 如果一个或多个副本在同步和非同步状态之间快速切换，说明集群内部出现 了问题，通常是 Java 不恰当的垃圾回收配置导致的。不恰当的垃圾回收配置 会造成几秒钟的停顿，从而让 broker 与 Zookeeper 之间断开连接，最后变成 不同步的，进而发生状态切换。
8. 一个滞后的同步副本会导致生产者和消费者变慢，因为在消息被认为已提交之前，客户端 会等待所有同步副本接收消息。而如果一个副本不再同步了，我们就不再关心它是否已经 收到消息。
9. 复制系数：主 题 级 别 的 配 置 参 数 是 replication.factor， 而 在 broker 级 别 则 可 以 通 过 default. replication.factor 来配置自动创建的主题。默认的复制系数是3。更高的复制系数会带来更高的可用性、可靠性和更少的故障。会占用 N倍的磁盘空间。
10. 默认情况下， Kafka 会确保分区的每个副本被放在不同的 broker 上。。如果配置了机架名字， Kafka 会保证分区的副本被分布在多 个机架上，从而获得更高的可用性。
11. unclean.leader.election 只能在 认值是 true。
12. 如果我们允许不同步的副本成为首领，那么就要承担丢失数据和出现数据不一 致的风险。如果不允许它们成为首领，那么就要接受较低的可用性，因为我们必须等待原 先的首领恢复到可用状态。如果把 unclean.leader.election.enable 设为 true，就是允许不同步的副本成为首领（也 就是“不完全的选举”）
13. 最少同步副本：在主题级别和broker 级别上，这个参数都叫 min.insync.replicas。如果 min.insync.replicas 被设为 2， 那么至少要存 在两个同步副本才能向分区写入数据。如果同步副本数量少于2，那么 broker 就会停止接受生产者的请求。尝试发送数据的生产 者会收到 NotEnoughReplicasException 异常。
14. 每个使用Kafka的开发人员都要注意两件事情：
    1. 根据可靠性需求配置恰当的acks值。
    2. 在参数配置和代码里正确处理错误。
15. 生产者可以选择以下3 种不同的确认模式。 
    1. acks=0 意味着如果生产者能够通过网络把消息发送出去，那么就认为消息已成功写入 Kafka。 在这种情况下还是有可能发生错误，比如发送的对象无法被序列化或者网卡发 生故障，但如果是分区离线或整个集群长时间不可用，那就不会收到任何错误。即使是 在发生完全首领选举的情况下，这种模式仍然会丢失消息，因为在新首领选举过程中它 并不知道首领已经不可用了。在 acks=0 模式下的运行速度是非常快的（这就是为什么 很多基准测试都是基于这个模式），你可以得到惊人的吞吐量和带宽利用率，不过如果 选择了这种模式，一定会丢失一些消息。
    2. acks=1 意味着首领在收到消息并把它写入到分区数据文件（不一定同步到磁盘上）时 会返回确认或错误响应。在这个模式下，如果发生正常的首领选举，生产者会在选举时 收到一个 LeaderNotAvailableException 异常， 如果生产者能恰当地处理这个错误（参 考 6.4.2 节），它会重试发送消息，最终消息会安全到达新的首领那里。不过在这个模式 下仍然有可能丢失数据，比如消息已经成功写入首领，但在消息被复制到跟随者副本之 前首领发生崩溃。
    3. acks=all 意味着首领在返回确认或错误响应之前，会等待所有同步副本都收到消息。如 果和 min.insync.replicas 参数结合起来，就可以决定在返回确认前至少有多少个副本 能够收到消息。这是最保险的做法——生产者会一直重试直到消息被成功提交。不过这 也是最慢的做法，生产者在继续发送其他消息之前需要等待所有副本都收到当前的消息。 可以通过使用异步模式和更大的批次来加快速度，但这样做通常会降低吞吐量。
16. 生产者需要处理的错误包括两部分：一部分是生产者可以自动处理的错误，还有一部分是 需要开发者手动处理的错误。
17. 如果 broker 返回的错误可以通过 重试 来解决，那么生产者会自动处理这些错误。生产者向 broker 发送消息时， broker 可以返回一个成功响应码或者一个错误响应码。错误响应码可以 分为两种，一种是在重试之后可以解决的，还有一种是无法通过重试解决的。
18. 一般情况下， 如果你的目标是不丢失任何消息， 那么最好让生产者在遇到可重试错误时 能够保持重试。
19. Kafka 的跨数据中心复制工具（MirrorMaker）默认会进行无限制的 重试（例如 retries=MAX_INT）。作为一个具有高可靠性的复制工具，它决不会丢失消息。
20. 。 重试和恰当的错误处理可以保 证每个消息“至少被保存一次”，但当前的 Kafka 版本（0.10.0）无法保证每个消息“只被 保存一次”。现实中的很多应用程序在消息里加入唯一标识符，用于检测重复消息，消费 者在读取消息时可以对它们进行清理。还要一些应用程序可以做到消息的“幂等”，也就 是说，即使出现了重复消息，也不会对处理结果的正确性造成负面影响。
21. 消费者唯一要做的是跟踪哪些消息是已经读取过的，哪些是还没有读取过的。这是在读取 消息时不丢失消息的关键。（偏移量是消费者唯一的凭仗）
22. 为了保证消费者行为的可靠性，需要注意以下4个非常重要的配置参数。
    1. 第 1 个是 group.id。 这个参数在第 4 章已经详细解释过了， 如果两个消费者具有相同的 group.id，并且订阅了同一个主题，那么每个消费者会分到主题分区的一个子集，也就是 说它们只能读到所有消息的一个子集（不过群组会读取主题所有的消息）。如果你希望消 费者可以看到主题的所有消息，那么需要为它们设置唯一的 group.id。
    2. 第 2 个是 auto.offset.reset。这个参数指定了在没有偏移量可提交时（比如消费者第 1 次 启动时）或者请求的偏移量在 broker 上不存在时（第 4 章已经解释过这种场景），消费者 会做些什么。
    3. 第 3 个是 enable.auto.commit。这是一个非常重要的配置参数，你可以让消费者基于任务 调度自动提交偏移量，也可以在代码里手动提交偏移量。
    4. 第 4 个配置参数 auto.commit.interval.ms 与第 3 个参数有直接的联系。如果选择了自动提 交偏移量，可以通过该参数配置提交的频度，默认值是每 5 秒钟提交一次。
23. Kafka提供了两个重要的工具用于验证配置：org.apache.kafka.tools 包里的 Verifiable Producer 和 VerifiableConsumer 这两个类。
24. 对于生产者来说， 最重要的两个可靠性指标是消息的 error-rate 和 retry-rate（聚 合过的）。对于消费者来说，最重要的指标是 consumer-lag， 该指标表明了消费者的处理速度与最近 提交到分区里的偏移量之间还有多少差距。